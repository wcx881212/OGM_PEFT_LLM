{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "layer1 = nn.Linear(8,3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1., 1., 1., 1.]])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((3,8))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "8"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.weight.size(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[-0.0581,  0.0361, -0.0649,  0.0933],\n         [ 0.2731, -0.2574, -0.2784, -0.2805],\n         [ 0.2419,  0.2746,  0.2415,  0.3205]], grad_fn=<SliceBackward0>),\n tensor([[-0.3356, -0.2775,  0.2027,  0.0922],\n         [-0.1183,  0.1392, -0.2094,  0.2146],\n         [-0.0479,  0.0785,  0.1698, -0.1927]], grad_fn=<SliceBackward0>))"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.weight[:,4:], layer1.weight[:,:4]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 1., 1., 0., 0., 0., 0., 0., 0.],\n        [1., 1., 1., 0., 0., 0., 0., 0., 0.]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones((2,3))\n",
    "y = torch.zeros((2,6))\n",
    "z = torch.cat((x,y),dim=1)\n",
    "z"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([18, 10]), torch.Size([18, 10]))"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones((18,20))\n",
    "gama, beta = torch.split(x,10,1)\n",
    "gama.shape, beta.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 294912 || all params: 109777152 || trainable%: 0.2686460658042941\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertConfig, BertTokenizer\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "from peft.utils.config import PromptLearningConfig\n",
    "\n",
    "bertconfig = BertConfig.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.TOKEN_CLS, inference_mode=True, r=8, lora_alpha=32, lora_dropout=0.1\n",
    ")\n",
    "# print(isinstance(peft_config, PromptLearningConfig)) # False\n",
    "\n",
    "model = BertModel.from_pretrained('bert-base-uncased', config=bertconfig)\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "# trainable params: 294912 || all params: 109777152 || trainable%: 0.2686460658042941"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 1045, 2293, 1996, 11559, 2154, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}\n",
      "torch.Size([2, 7])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "sentence1 = \"I love the sunny day\"\n",
    "sentence2 = \"I love my mom dad\"\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',padding=True,truncation=True,max_length=512,return_tensors=\"pt\")\n",
    "input1 = tokenizer.encode_plus(sentence1)\n",
    "input2 = tokenizer.encode_plus(sentence2)\n",
    "print(input1)\n",
    "input_ids=torch.concat((torch.unsqueeze(torch.LongTensor(input1['input_ids']),dim=0),torch.unsqueeze(torch.LongTensor(input2['input_ids']),dim=0)),dim=0)\n",
    "print(input_ids.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.1219,  0.2386, -0.0089,  ..., -0.3565,  0.2120,  0.2568],\n",
      "         [ 0.3584,  0.1863, -0.2557,  ..., -0.4161,  0.5436,  0.0312],\n",
      "         [ 1.2115,  0.7444,  1.1416,  ..., -0.1788,  0.4152, -0.1766],\n",
      "         ...,\n",
      "         [-1.3715, -0.0884, -0.2859,  ...,  0.5654, -0.0344, -0.1637],\n",
      "         [-0.4437, -0.2219, -0.1582,  ...,  0.6177,  0.3368, -0.4463],\n",
      "         [ 0.6994, -0.0115, -0.0842,  ..., -0.1018, -0.4322, -0.3810]],\n",
      "\n",
      "        [[ 0.0987,  0.3710, -0.1172,  ..., -0.2921,  0.2551,  0.1856],\n",
      "         [ 0.1952,  0.3604, -0.4829,  ...,  0.1172,  0.9087,  0.2542],\n",
      "         [ 0.9428,  0.7529,  0.6970,  ..., -0.5273,  0.7027,  0.0036],\n",
      "         ...,\n",
      "         [ 0.4026, -0.0351,  0.1042,  ..., -0.3336,  0.6649,  0.0607],\n",
      "         [-0.0187, -0.4869, -0.1939,  ...,  0.6178,  0.6148, -0.1918],\n",
      "         [ 0.6716,  0.1270, -0.1164,  ..., -0.2789, -0.5492, -0.3206]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.9071, -0.3191, -0.1169,  ...,  0.0450, -0.6961,  0.9345],\n",
      "        [-0.8240, -0.2614, -0.0117,  ...,  0.2263, -0.5960,  0.8422]],\n",
      "       grad_fn=<TanhBackward0>), hidden_states=(tensor([[[ 1.6855e-01, -2.8577e-01, -3.2613e-01,  ..., -2.7571e-02,\n",
      "           3.8253e-02,  1.6400e-01],\n",
      "         [-3.4026e-04,  5.3974e-01, -2.8805e-01,  ...,  7.5731e-01,\n",
      "           8.9008e-01,  1.6575e-01],\n",
      "         [ 1.1558e+00,  8.5331e-02, -1.1208e-01,  ...,  4.3965e-01,\n",
      "           8.5903e-01, -3.2685e-01],\n",
      "         ...,\n",
      "         [-1.5124e+00,  2.7332e-01, -5.7287e-01,  ..., -3.9683e-01,\n",
      "          -5.5797e-01,  6.0342e-01],\n",
      "         [-3.2710e-01,  9.7806e-02, -4.9911e-03,  ...,  2.7142e-01,\n",
      "           7.6029e-02, -6.0058e-01],\n",
      "         [-1.4815e-01, -2.9485e-01, -1.6900e-01,  ..., -5.0090e-01,\n",
      "           2.5442e-01, -7.0021e-02]],\n",
      "\n",
      "        [[ 1.6855e-01, -2.8577e-01, -3.2613e-01,  ..., -2.7571e-02,\n",
      "           3.8253e-02,  1.6400e-01],\n",
      "         [-3.4026e-04,  5.3974e-01, -2.8805e-01,  ...,  7.5731e-01,\n",
      "           8.9008e-01,  1.6575e-01],\n",
      "         [ 1.1558e+00,  8.5331e-02, -1.1208e-01,  ...,  4.3965e-01,\n",
      "           8.5903e-01, -3.2685e-01],\n",
      "         ...,\n",
      "         [-8.9888e-01, -7.9533e-01, -7.2587e-01,  ...,  8.7856e-01,\n",
      "          -2.7480e-02,  9.5527e-01],\n",
      "         [-4.1965e-02, -6.9567e-01, -6.4149e-01,  ...,  2.8855e-01,\n",
      "           5.3211e-01,  8.2801e-01],\n",
      "         [-1.4815e-01, -2.9485e-01, -1.6900e-01,  ..., -5.0090e-01,\n",
      "           2.5442e-01, -7.0021e-02]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[ 2.3203e-01,  1.3332e-01, -1.2761e-01,  ...,  3.9610e-02,\n",
      "           1.0462e-01,  1.2476e-01],\n",
      "         [ 4.7599e-01,  1.0265e+00, -1.5093e-01,  ...,  6.3234e-01,\n",
      "           7.7928e-01,  2.3078e-01],\n",
      "         [ 9.7663e-01,  9.1365e-01,  4.5403e-01,  ...,  6.1492e-01,\n",
      "           9.2686e-01,  1.6766e-03],\n",
      "         ...,\n",
      "         [-1.0550e+00,  9.2833e-01, -8.7117e-03,  ...,  1.3370e-01,\n",
      "          -4.2002e-01,  3.8379e-01],\n",
      "         [-7.3828e-01,  3.4808e-01,  4.1268e-01,  ...,  3.4636e-01,\n",
      "          -1.1202e-01, -1.6023e+00],\n",
      "         [ 6.7217e-02,  1.7994e-01, -1.2879e-01,  ..., -4.0384e-01,\n",
      "           6.8900e-01, -3.8821e-02]],\n",
      "\n",
      "        [[ 1.7172e-01,  9.0956e-02, -1.1759e-01,  ..., -1.0796e-03,\n",
      "           1.7685e-01,  8.6369e-02],\n",
      "         [ 6.8457e-01,  1.4250e+00, -2.0812e-01,  ...,  8.3351e-01,\n",
      "           1.2976e+00,  3.9778e-01],\n",
      "         [ 1.6223e+00,  1.0513e+00,  5.0245e-01,  ...,  5.8827e-01,\n",
      "           1.3812e+00,  2.5544e-01],\n",
      "         ...,\n",
      "         [ 1.4181e-01, -3.9972e-01, -4.0812e-01,  ...,  1.0472e+00,\n",
      "           7.2717e-01,  1.4703e+00],\n",
      "         [ 9.4291e-01, -2.7535e-01, -1.5296e-02,  ...,  7.6044e-01,\n",
      "           1.1980e+00,  1.2496e+00],\n",
      "         [ 3.2780e-01,  3.7338e-02, -8.1209e-02,  ..., -4.1533e-01,\n",
      "           7.7347e-01,  1.8941e-01]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.1086, -0.1081, -0.1190,  ...,  0.1126,  0.1066,  0.0270],\n",
      "         [ 0.4448,  0.9285,  0.2320,  ...,  0.5359,  0.3556,  0.0383],\n",
      "         [ 1.4898,  1.1282,  0.8773,  ...,  1.1336,  0.6342, -0.1626],\n",
      "         ...,\n",
      "         [-0.9832,  1.7723,  0.2755,  ...,  0.8360, -0.7945,  0.0506],\n",
      "         [-0.9482,  0.7738,  0.5901,  ...,  0.4183, -0.1164, -1.6241],\n",
      "         [-0.0536,  0.0515,  0.1525,  ..., -0.0770,  0.6507, -0.1750]],\n",
      "\n",
      "        [[ 0.1020, -0.1597, -0.1691,  ...,  0.0182,  0.1260,  0.0631],\n",
      "         [ 0.5174,  1.2512,  0.1328,  ...,  0.6460,  0.7088,  0.0541],\n",
      "         [ 2.0878,  1.4277,  0.9967,  ...,  0.9528,  1.2376, -0.0700],\n",
      "         ...,\n",
      "         [ 0.4551,  0.2219,  0.0221,  ...,  0.9467,  0.9082,  0.8869],\n",
      "         [ 0.9867,  0.4834,  0.5200,  ...,  0.7998,  1.5936,  0.7543],\n",
      "         [ 0.0895,  0.0136,  0.0868,  ..., -0.1952,  0.5334,  0.0346]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0558, -0.2087,  0.0072,  ...,  0.2220,  0.1256,  0.1712],\n",
      "         [ 0.6178,  0.5046,  0.6610,  ...,  0.6184,  0.1764,  0.0756],\n",
      "         [ 1.9062,  0.7761,  1.4207,  ...,  0.5916,  0.0226, -0.1816],\n",
      "         ...,\n",
      "         [-1.0920,  0.7113,  0.5403,  ...,  0.7010, -1.1861, -0.2892],\n",
      "         [-0.9248,  0.7257,  0.6846,  ...,  0.2257, -0.2876, -1.6859],\n",
      "         [-0.0503, -0.0873,  0.1219,  ...,  0.0333,  0.1239, -0.0308]],\n",
      "\n",
      "        [[ 0.0444, -0.2822, -0.0391,  ...,  0.1600,  0.0428,  0.2291],\n",
      "         [ 0.3306,  0.8944,  0.8340,  ...,  0.9711,  0.3181, -0.1047],\n",
      "         [ 2.4851,  1.2144,  1.4282,  ...,  0.5218,  0.4613, -0.2458],\n",
      "         ...,\n",
      "         [ 0.2288,  0.2959, -0.3054,  ...,  1.1206,  0.5165,  0.5746],\n",
      "         [ 0.6714,  0.3619,  0.3645,  ...,  0.7723,  0.7092,  0.3374],\n",
      "         [-0.0304, -0.1041,  0.1121,  ...,  0.0131,  0.0702,  0.0036]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 2.9633e-01, -4.9555e-01, -5.3853e-01,  ...,  4.3219e-01,\n",
      "           2.3910e-01,  4.8840e-01],\n",
      "         [ 7.7177e-01,  3.3019e-01,  6.2238e-01,  ...,  5.6230e-01,\n",
      "          -2.1703e-02, -2.1766e-01],\n",
      "         [ 2.0013e+00,  7.6012e-01,  7.9327e-01,  ...,  6.5340e-01,\n",
      "          -5.8724e-01,  5.3473e-01],\n",
      "         ...,\n",
      "         [-1.2481e+00,  5.7762e-01,  3.6269e-02,  ...,  7.1459e-01,\n",
      "          -9.3507e-01, -2.7944e-01],\n",
      "         [-9.7053e-01,  6.6733e-01,  1.9134e-01,  ...,  5.8044e-01,\n",
      "          -4.4913e-01, -1.6582e+00],\n",
      "         [-2.8484e-02, -5.0910e-02,  5.9955e-03,  ...,  7.6411e-04,\n",
      "           6.0867e-02, -3.1665e-02]],\n",
      "\n",
      "        [[ 3.5530e-01, -5.1605e-01, -5.9114e-01,  ...,  4.5237e-01,\n",
      "          -2.3437e-01,  6.4129e-01],\n",
      "         [ 6.2117e-01,  4.5921e-01,  1.0431e+00,  ...,  8.8477e-01,\n",
      "           9.3932e-02, -3.1158e-01],\n",
      "         [ 2.5266e+00,  8.6942e-01,  1.0432e+00,  ...,  6.5426e-01,\n",
      "          -2.1588e-01,  8.4529e-02],\n",
      "         ...,\n",
      "         [ 6.2122e-01,  5.0598e-02, -7.4174e-01,  ...,  7.3033e-01,\n",
      "           4.7439e-01,  5.3983e-01],\n",
      "         [ 4.7623e-01,  7.3317e-02,  2.4803e-01,  ...,  7.9138e-02,\n",
      "           4.4511e-01,  7.3181e-01],\n",
      "         [-2.4007e-02, -5.3287e-02,  1.6608e-02,  ...,  4.1853e-03,\n",
      "           5.8647e-02, -3.5526e-02]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.1105, -0.4329, -0.5328,  ..., -0.1623,  0.2690,  0.6364],\n",
      "         [ 0.5556, -0.3090,  0.3942,  ...,  0.3967, -0.1195, -0.1733],\n",
      "         [ 1.8044,  0.7209,  0.3362,  ...,  0.6112, -0.8114,  0.3037],\n",
      "         ...,\n",
      "         [-1.1746,  0.7314,  0.1331,  ...,  0.8033, -0.9427, -0.1504],\n",
      "         [-1.1369,  0.8802,  0.4385,  ...,  0.6861, -0.4708, -1.7654],\n",
      "         [-0.0209, -0.0388,  0.0154,  ...,  0.0168,  0.0106, -0.0342]],\n",
      "\n",
      "        [[ 0.2789, -0.4651, -0.6154,  ..., -0.1406, -0.0945,  0.6439],\n",
      "         [ 0.7961, -0.1337,  0.6573,  ...,  0.4991,  0.1154, -0.2753],\n",
      "         [ 2.4226,  1.0364,  0.6802,  ...,  0.4683, -0.5147, -0.0944],\n",
      "         ...,\n",
      "         [ 0.3273,  0.2059, -0.2094,  ...,  0.4851,  0.4073,  0.1362],\n",
      "         [ 0.5874,  0.2598,  0.2744,  ..., -0.0994,  0.2442,  0.6616],\n",
      "         [-0.0174, -0.0404,  0.0223,  ...,  0.0155,  0.0091, -0.0413]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 2.1628e-01, -3.6689e-01, -4.9812e-01,  ..., -3.1371e-01,\n",
      "           3.9327e-01,  6.9357e-01],\n",
      "         [ 6.8227e-01,  1.8098e-01,  1.6720e-01,  ...,  2.9446e-01,\n",
      "           2.2936e-01, -5.2136e-01],\n",
      "         [ 1.5263e+00,  5.6994e-01,  4.2213e-01,  ...,  6.3828e-01,\n",
      "          -9.6981e-01,  3.3614e-01],\n",
      "         ...,\n",
      "         [-1.4674e+00,  7.8286e-01,  2.4790e-01,  ...,  4.6880e-01,\n",
      "          -5.9978e-01, -2.5060e-01],\n",
      "         [-1.2278e+00,  1.1309e+00, -2.0121e-01,  ...,  1.5259e-01,\n",
      "          -7.3778e-01, -1.9138e+00],\n",
      "         [ 5.5690e-03, -3.8597e-02, -1.1969e-02,  ...,  3.8772e-03,\n",
      "          -2.0210e-02, -4.0899e-02]],\n",
      "\n",
      "        [[ 2.4318e-01, -5.2596e-01, -5.4125e-01,  ..., -1.3915e-01,\n",
      "           2.2223e-01,  5.8354e-01],\n",
      "         [ 5.6451e-01,  1.2459e-01,  7.0848e-01,  ...,  3.5983e-01,\n",
      "           2.9672e-01, -5.5536e-01],\n",
      "         [ 2.3776e+00,  9.4025e-01,  6.5911e-01,  ...,  4.0046e-01,\n",
      "          -8.0021e-01, -1.2344e-01],\n",
      "         ...,\n",
      "         [ 1.7884e-01,  6.9589e-02,  3.3930e-02,  ..., -1.0597e-02,\n",
      "           6.9571e-01, -1.2944e-03],\n",
      "         [ 6.8916e-01,  3.8971e-01,  3.7022e-02,  ..., -2.3424e-01,\n",
      "           2.4097e-01,  8.9244e-01],\n",
      "         [ 1.1445e-02, -4.0391e-02, -6.6698e-03,  ...,  5.7427e-03,\n",
      "          -2.0165e-02, -4.4169e-02]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.2028, -0.3390, -0.1676,  ..., -0.1742,  0.3890,  1.1094],\n",
      "         [ 0.6196,  0.2030,  0.1282,  ...,  0.3746,  0.3616, -0.3521],\n",
      "         [ 1.2394,  0.7520,  0.5033,  ...,  1.0842, -0.4682,  0.1903],\n",
      "         ...,\n",
      "         [-1.5839,  0.7820,  0.3723,  ...,  0.4699, -0.1107, -0.3192],\n",
      "         [-1.1248,  0.7186, -0.2436,  ...,  0.0179, -0.4867, -1.5820],\n",
      "         [-0.0031, -0.0352, -0.0078,  ..., -0.0057,  0.0220, -0.0521]],\n",
      "\n",
      "        [[ 0.2959, -0.3541, -0.6547,  ..., -0.0363,  0.6077,  0.5615],\n",
      "         [ 0.4977,  0.1765, -0.0794,  ...,  0.5598,  0.7012, -0.4501],\n",
      "         [ 2.2928,  1.1565,  0.2990,  ...,  0.7065, -0.1105, -0.1272],\n",
      "         ...,\n",
      "         [ 0.0615,  0.3471, -0.0891,  ..., -0.1169,  0.9664,  0.4821],\n",
      "         [ 0.3711,  0.0732, -0.7383,  ...,  0.1108,  0.5227,  0.7674],\n",
      "         [-0.0141, -0.0418, -0.0239,  ..., -0.0097,  0.0327, -0.0602]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 4.1292e-01, -5.4622e-02, -5.0157e-01,  ..., -7.1439e-01,\n",
      "           4.6607e-01,  1.0539e+00],\n",
      "         [ 5.3571e-01,  4.1139e-01, -2.5151e-01,  ...,  2.7454e-01,\n",
      "           5.6216e-01,  3.3817e-01],\n",
      "         [ 1.0175e+00,  6.7412e-01,  7.0450e-01,  ...,  2.1129e-01,\n",
      "           1.7408e-02,  4.1807e-01],\n",
      "         ...,\n",
      "         [-1.5333e+00,  3.8977e-01,  2.4150e-01,  ...,  4.6558e-01,\n",
      "           5.8152e-01, -3.5964e-01],\n",
      "         [-9.1321e-01,  7.2174e-01, -2.2789e-01,  ...,  5.6412e-02,\n",
      "           4.5289e-02, -1.2884e+00],\n",
      "         [ 9.4955e-04, -3.7185e-02,  1.5809e-02,  ..., -4.5941e-02,\n",
      "          -1.9666e-02, -7.3528e-02]],\n",
      "\n",
      "        [[ 2.8309e-01,  1.3549e-01, -8.8523e-01,  ..., -4.9927e-01,\n",
      "           5.2388e-01,  6.0791e-01],\n",
      "         [ 4.8635e-01,  3.2763e-01, -4.7143e-01,  ...,  3.1498e-01,\n",
      "           6.3088e-01,  1.2505e-01],\n",
      "         [ 1.8634e+00,  1.1177e+00,  7.2655e-01,  ...,  1.1974e-01,\n",
      "           2.3865e-01,  3.5358e-01],\n",
      "         ...,\n",
      "         [ 2.5663e-01,  1.1943e-01, -5.9452e-02,  ..., -3.4445e-01,\n",
      "           8.6021e-01,  5.2154e-01],\n",
      "         [-1.4552e-01, -1.7384e-01, -7.8994e-01,  ..., -1.7445e-01,\n",
      "          -1.8410e-01,  5.3319e-01],\n",
      "         [-1.1598e-02, -4.1767e-02,  2.3463e-02,  ..., -4.0192e-02,\n",
      "          -2.7849e-02, -9.3924e-02]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.5008,  0.2269, -0.5118,  ..., -0.5200,  0.2832,  0.8692],\n",
      "         [ 0.5419,  0.6235, -0.3539,  ..., -0.0282,  0.4963,  0.3419],\n",
      "         [ 0.8375,  0.8214,  0.3712,  ...,  0.0638,  0.0147,  0.2802],\n",
      "         ...,\n",
      "         [-1.1949,  0.1524,  0.7388,  ...,  0.2292,  0.3395, -0.1334],\n",
      "         [-0.6110,  0.5662, -0.1860,  ...,  0.2520,  0.0335, -0.9786],\n",
      "         [ 0.0033, -0.0204,  0.0184,  ..., -0.0539, -0.0487, -0.0156]],\n",
      "\n",
      "        [[ 0.2171,  0.3766, -0.5892,  ..., -0.4448,  0.3907,  0.3675],\n",
      "         [ 0.2053,  0.6754, -0.3057,  ...,  0.2911,  0.6554, -0.0365],\n",
      "         [ 1.5063,  1.4088,  0.8182,  ...,  0.0200,  0.5841,  0.1498],\n",
      "         ...,\n",
      "         [ 0.2333,  0.3114, -0.1430,  ..., -0.5253,  0.8699,  0.4649],\n",
      "         [-0.3078,  0.1437, -0.8212,  ..., -0.2975, -0.1149,  0.0215],\n",
      "         [ 0.0255, -0.0075,  0.0286,  ..., -0.0505, -0.0678, -0.0921]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.4518,  0.1972, -0.4294,  ..., -0.3170, -0.3371,  0.6794],\n",
      "         [ 0.6174,  0.1953, -0.0026,  ..., -0.0462,  0.4377, -0.1954],\n",
      "         [ 0.9639,  0.7145,  0.8041,  ..., -0.2706,  0.1283, -0.1311],\n",
      "         ...,\n",
      "         [-1.1051,  0.1430,  0.3951,  ...,  0.7024,  0.0477, -0.2445],\n",
      "         [-0.3018,  0.2063, -0.2390,  ...,  0.7351,  0.0298, -1.0876],\n",
      "         [ 0.0097, -0.0511,  0.0288,  ...,  0.1276, -0.0232, -0.0347]],\n",
      "\n",
      "        [[ 0.2748,  0.2499, -0.4410,  ..., -0.3421, -0.0567,  0.3229],\n",
      "         [ 0.2858,  0.5522, -0.1952,  ...,  0.2977,  0.6269, -0.3012],\n",
      "         [ 1.6457,  1.2286,  0.8697,  ..., -0.2663,  0.9829,  0.0328],\n",
      "         ...,\n",
      "         [ 0.4828,  0.1768, -0.0869,  ..., -0.4198,  0.7256,  0.3343],\n",
      "         [-0.1316, -0.2022, -0.7848,  ...,  0.0211, -0.0276,  0.0983],\n",
      "         [ 0.0087,  0.0027, -0.0078,  ...,  0.1014, -0.0203, -0.0347]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.5262,  0.3111,  0.0635,  ..., -0.5139, -0.2360,  0.1765],\n",
      "         [ 0.6557,  0.1646,  0.0357,  ..., -0.2917,  0.2744, -0.0124],\n",
      "         [ 1.2714,  0.9330,  0.9488,  ..., -0.3509,  0.3581,  0.2470],\n",
      "         ...,\n",
      "         [-1.1342,  0.4081,  0.1333,  ...,  0.6335,  0.0498, -0.0019],\n",
      "         [-0.1300,  0.1144, -0.1573,  ...,  0.5191, -0.0888, -1.0061],\n",
      "         [ 0.0171,  0.0067, -0.0190,  ...,  0.0153, -0.0138,  0.0093]],\n",
      "\n",
      "        [[ 0.1748,  0.3665, -0.1829,  ..., -0.4121,  0.0174,  0.2354],\n",
      "         [ 0.1475,  0.4850, -0.1631,  ..., -0.0864,  0.6014,  0.0495],\n",
      "         [ 1.0484,  1.1951,  0.7417,  ..., -0.7135,  1.0665,  0.3081],\n",
      "         ...,\n",
      "         [ 0.4051,  0.1502,  0.0211,  ..., -0.3017,  0.7728,  0.4167],\n",
      "         [-0.3869, -0.5863, -0.1663,  ...,  0.4047,  0.2398, -0.2340],\n",
      "         [ 0.0233,  0.0112, -0.0166,  ...,  0.0037, -0.0303,  0.0169]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.1219,  0.2386, -0.0089,  ..., -0.3565,  0.2120,  0.2568],\n",
      "         [ 0.3584,  0.1863, -0.2557,  ..., -0.4161,  0.5436,  0.0312],\n",
      "         [ 1.2115,  0.7444,  1.1416,  ..., -0.1788,  0.4152, -0.1766],\n",
      "         ...,\n",
      "         [-1.3715, -0.0884, -0.2859,  ...,  0.5654, -0.0344, -0.1637],\n",
      "         [-0.4437, -0.2219, -0.1582,  ...,  0.6177,  0.3368, -0.4463],\n",
      "         [ 0.6994, -0.0115, -0.0842,  ..., -0.1018, -0.4322, -0.3810]],\n",
      "\n",
      "        [[ 0.0987,  0.3710, -0.1172,  ..., -0.2921,  0.2551,  0.1856],\n",
      "         [ 0.1952,  0.3604, -0.4829,  ...,  0.1172,  0.9087,  0.2542],\n",
      "         [ 0.9428,  0.7529,  0.6970,  ..., -0.5273,  0.7027,  0.0036],\n",
      "         ...,\n",
      "         [ 0.4026, -0.0351,  0.1042,  ..., -0.3336,  0.6649,  0.0607],\n",
      "         [-0.0187, -0.4869, -0.1939,  ...,  0.6178,  0.6148, -0.1918],\n",
      "         [ 0.6716,  0.1270, -0.1164,  ..., -0.2789, -0.5492, -0.3206]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)), past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "origin_model = BertModel.from_pretrained('bert-base-uncased', config=bertconfig)\n",
    "x = origin_model(input_ids=input_ids)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.1219,  0.2386, -0.0089,  ..., -0.3565,  0.2120,  0.2568],\n",
      "         [ 0.3584,  0.1863, -0.2557,  ..., -0.4161,  0.5436,  0.0312],\n",
      "         [ 1.2115,  0.7444,  1.1416,  ..., -0.1788,  0.4152, -0.1766],\n",
      "         ...,\n",
      "         [-1.3715, -0.0884, -0.2859,  ...,  0.5654, -0.0344, -0.1637],\n",
      "         [-0.4437, -0.2219, -0.1582,  ...,  0.6177,  0.3368, -0.4463],\n",
      "         [ 0.6994, -0.0115, -0.0842,  ..., -0.1018, -0.4322, -0.3810]],\n",
      "\n",
      "        [[ 0.0987,  0.3710, -0.1172,  ..., -0.2921,  0.2551,  0.1856],\n",
      "         [ 0.1952,  0.3604, -0.4829,  ...,  0.1172,  0.9087,  0.2542],\n",
      "         [ 0.9428,  0.7529,  0.6970,  ..., -0.5273,  0.7027,  0.0036],\n",
      "         ...,\n",
      "         [ 0.4026, -0.0351,  0.1042,  ..., -0.3336,  0.6649,  0.0607],\n",
      "         [-0.0187, -0.4869, -0.1939,  ...,  0.6178,  0.6148, -0.1918],\n",
      "         [ 0.6716,  0.1270, -0.1164,  ..., -0.2789, -0.5492, -0.3206]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.9071, -0.3191, -0.1169,  ...,  0.0450, -0.6961,  0.9345],\n",
      "        [-0.8240, -0.2614, -0.0117,  ...,  0.2263, -0.5960,  0.8422]],\n",
      "       grad_fn=<TanhBackward0>), hidden_states=(tensor([[[ 1.6855e-01, -2.8577e-01, -3.2613e-01,  ..., -2.7571e-02,\n",
      "           3.8253e-02,  1.6400e-01],\n",
      "         [-3.4026e-04,  5.3974e-01, -2.8805e-01,  ...,  7.5731e-01,\n",
      "           8.9008e-01,  1.6575e-01],\n",
      "         [ 1.1558e+00,  8.5331e-02, -1.1208e-01,  ...,  4.3965e-01,\n",
      "           8.5903e-01, -3.2685e-01],\n",
      "         ...,\n",
      "         [-1.5124e+00,  2.7332e-01, -5.7287e-01,  ..., -3.9683e-01,\n",
      "          -5.5797e-01,  6.0342e-01],\n",
      "         [-3.2710e-01,  9.7806e-02, -4.9911e-03,  ...,  2.7142e-01,\n",
      "           7.6029e-02, -6.0058e-01],\n",
      "         [-1.4815e-01, -2.9485e-01, -1.6900e-01,  ..., -5.0090e-01,\n",
      "           2.5442e-01, -7.0021e-02]],\n",
      "\n",
      "        [[ 1.6855e-01, -2.8577e-01, -3.2613e-01,  ..., -2.7571e-02,\n",
      "           3.8253e-02,  1.6400e-01],\n",
      "         [-3.4026e-04,  5.3974e-01, -2.8805e-01,  ...,  7.5731e-01,\n",
      "           8.9008e-01,  1.6575e-01],\n",
      "         [ 1.1558e+00,  8.5331e-02, -1.1208e-01,  ...,  4.3965e-01,\n",
      "           8.5903e-01, -3.2685e-01],\n",
      "         ...,\n",
      "         [-8.9888e-01, -7.9533e-01, -7.2587e-01,  ...,  8.7856e-01,\n",
      "          -2.7480e-02,  9.5527e-01],\n",
      "         [-4.1965e-02, -6.9567e-01, -6.4149e-01,  ...,  2.8855e-01,\n",
      "           5.3211e-01,  8.2801e-01],\n",
      "         [-1.4815e-01, -2.9485e-01, -1.6900e-01,  ..., -5.0090e-01,\n",
      "           2.5442e-01, -7.0021e-02]]]), tensor([[[ 2.3203e-01,  1.3332e-01, -1.2761e-01,  ...,  3.9610e-02,\n",
      "           1.0462e-01,  1.2476e-01],\n",
      "         [ 4.7599e-01,  1.0265e+00, -1.5093e-01,  ...,  6.3234e-01,\n",
      "           7.7928e-01,  2.3078e-01],\n",
      "         [ 9.7663e-01,  9.1365e-01,  4.5403e-01,  ...,  6.1492e-01,\n",
      "           9.2686e-01,  1.6766e-03],\n",
      "         ...,\n",
      "         [-1.0550e+00,  9.2833e-01, -8.7117e-03,  ...,  1.3370e-01,\n",
      "          -4.2002e-01,  3.8379e-01],\n",
      "         [-7.3828e-01,  3.4808e-01,  4.1268e-01,  ...,  3.4636e-01,\n",
      "          -1.1202e-01, -1.6023e+00],\n",
      "         [ 6.7217e-02,  1.7994e-01, -1.2879e-01,  ..., -4.0384e-01,\n",
      "           6.8900e-01, -3.8821e-02]],\n",
      "\n",
      "        [[ 1.7172e-01,  9.0956e-02, -1.1759e-01,  ..., -1.0796e-03,\n",
      "           1.7685e-01,  8.6369e-02],\n",
      "         [ 6.8457e-01,  1.4250e+00, -2.0812e-01,  ...,  8.3351e-01,\n",
      "           1.2976e+00,  3.9778e-01],\n",
      "         [ 1.6223e+00,  1.0513e+00,  5.0245e-01,  ...,  5.8827e-01,\n",
      "           1.3812e+00,  2.5544e-01],\n",
      "         ...,\n",
      "         [ 1.4181e-01, -3.9972e-01, -4.0812e-01,  ...,  1.0472e+00,\n",
      "           7.2717e-01,  1.4703e+00],\n",
      "         [ 9.4291e-01, -2.7535e-01, -1.5296e-02,  ...,  7.6044e-01,\n",
      "           1.1980e+00,  1.2496e+00],\n",
      "         [ 3.2780e-01,  3.7338e-02, -8.1209e-02,  ..., -4.1533e-01,\n",
      "           7.7347e-01,  1.8941e-01]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.1086, -0.1081, -0.1190,  ...,  0.1126,  0.1066,  0.0270],\n",
      "         [ 0.4448,  0.9285,  0.2320,  ...,  0.5359,  0.3556,  0.0383],\n",
      "         [ 1.4898,  1.1282,  0.8773,  ...,  1.1336,  0.6342, -0.1626],\n",
      "         ...,\n",
      "         [-0.9832,  1.7723,  0.2755,  ...,  0.8360, -0.7945,  0.0506],\n",
      "         [-0.9482,  0.7738,  0.5901,  ...,  0.4183, -0.1164, -1.6241],\n",
      "         [-0.0536,  0.0515,  0.1525,  ..., -0.0770,  0.6507, -0.1750]],\n",
      "\n",
      "        [[ 0.1020, -0.1597, -0.1691,  ...,  0.0182,  0.1260,  0.0631],\n",
      "         [ 0.5174,  1.2512,  0.1328,  ...,  0.6460,  0.7088,  0.0541],\n",
      "         [ 2.0878,  1.4277,  0.9967,  ...,  0.9528,  1.2376, -0.0700],\n",
      "         ...,\n",
      "         [ 0.4551,  0.2219,  0.0221,  ...,  0.9467,  0.9082,  0.8869],\n",
      "         [ 0.9867,  0.4834,  0.5200,  ...,  0.7998,  1.5936,  0.7543],\n",
      "         [ 0.0895,  0.0136,  0.0868,  ..., -0.1952,  0.5334,  0.0346]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0558, -0.2087,  0.0072,  ...,  0.2220,  0.1256,  0.1712],\n",
      "         [ 0.6178,  0.5046,  0.6610,  ...,  0.6184,  0.1764,  0.0756],\n",
      "         [ 1.9062,  0.7761,  1.4207,  ...,  0.5916,  0.0226, -0.1816],\n",
      "         ...,\n",
      "         [-1.0920,  0.7113,  0.5403,  ...,  0.7010, -1.1861, -0.2892],\n",
      "         [-0.9248,  0.7257,  0.6846,  ...,  0.2257, -0.2876, -1.6859],\n",
      "         [-0.0503, -0.0873,  0.1219,  ...,  0.0333,  0.1239, -0.0308]],\n",
      "\n",
      "        [[ 0.0444, -0.2822, -0.0391,  ...,  0.1600,  0.0428,  0.2291],\n",
      "         [ 0.3306,  0.8944,  0.8340,  ...,  0.9711,  0.3181, -0.1047],\n",
      "         [ 2.4851,  1.2144,  1.4282,  ...,  0.5218,  0.4613, -0.2458],\n",
      "         ...,\n",
      "         [ 0.2288,  0.2959, -0.3054,  ...,  1.1206,  0.5165,  0.5746],\n",
      "         [ 0.6714,  0.3619,  0.3645,  ...,  0.7723,  0.7092,  0.3374],\n",
      "         [-0.0304, -0.1041,  0.1121,  ...,  0.0131,  0.0702,  0.0036]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 2.9633e-01, -4.9555e-01, -5.3853e-01,  ...,  4.3219e-01,\n",
      "           2.3910e-01,  4.8840e-01],\n",
      "         [ 7.7177e-01,  3.3019e-01,  6.2238e-01,  ...,  5.6230e-01,\n",
      "          -2.1703e-02, -2.1766e-01],\n",
      "         [ 2.0013e+00,  7.6012e-01,  7.9327e-01,  ...,  6.5340e-01,\n",
      "          -5.8724e-01,  5.3473e-01],\n",
      "         ...,\n",
      "         [-1.2481e+00,  5.7762e-01,  3.6269e-02,  ...,  7.1459e-01,\n",
      "          -9.3507e-01, -2.7944e-01],\n",
      "         [-9.7053e-01,  6.6733e-01,  1.9134e-01,  ...,  5.8044e-01,\n",
      "          -4.4913e-01, -1.6582e+00],\n",
      "         [-2.8484e-02, -5.0910e-02,  5.9955e-03,  ...,  7.6411e-04,\n",
      "           6.0867e-02, -3.1665e-02]],\n",
      "\n",
      "        [[ 3.5530e-01, -5.1605e-01, -5.9114e-01,  ...,  4.5237e-01,\n",
      "          -2.3437e-01,  6.4129e-01],\n",
      "         [ 6.2117e-01,  4.5921e-01,  1.0431e+00,  ...,  8.8477e-01,\n",
      "           9.3932e-02, -3.1158e-01],\n",
      "         [ 2.5266e+00,  8.6942e-01,  1.0432e+00,  ...,  6.5426e-01,\n",
      "          -2.1588e-01,  8.4529e-02],\n",
      "         ...,\n",
      "         [ 6.2122e-01,  5.0598e-02, -7.4174e-01,  ...,  7.3033e-01,\n",
      "           4.7439e-01,  5.3983e-01],\n",
      "         [ 4.7623e-01,  7.3317e-02,  2.4803e-01,  ...,  7.9138e-02,\n",
      "           4.4511e-01,  7.3181e-01],\n",
      "         [-2.4007e-02, -5.3287e-02,  1.6608e-02,  ...,  4.1853e-03,\n",
      "           5.8647e-02, -3.5526e-02]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.1105, -0.4329, -0.5328,  ..., -0.1623,  0.2690,  0.6364],\n",
      "         [ 0.5556, -0.3090,  0.3942,  ...,  0.3967, -0.1195, -0.1733],\n",
      "         [ 1.8044,  0.7209,  0.3362,  ...,  0.6112, -0.8114,  0.3037],\n",
      "         ...,\n",
      "         [-1.1746,  0.7314,  0.1331,  ...,  0.8033, -0.9427, -0.1504],\n",
      "         [-1.1369,  0.8802,  0.4385,  ...,  0.6861, -0.4708, -1.7654],\n",
      "         [-0.0209, -0.0388,  0.0154,  ...,  0.0168,  0.0106, -0.0342]],\n",
      "\n",
      "        [[ 0.2789, -0.4651, -0.6154,  ..., -0.1406, -0.0945,  0.6439],\n",
      "         [ 0.7961, -0.1337,  0.6573,  ...,  0.4991,  0.1154, -0.2753],\n",
      "         [ 2.4226,  1.0364,  0.6802,  ...,  0.4683, -0.5147, -0.0944],\n",
      "         ...,\n",
      "         [ 0.3273,  0.2059, -0.2094,  ...,  0.4851,  0.4073,  0.1362],\n",
      "         [ 0.5874,  0.2598,  0.2744,  ..., -0.0994,  0.2442,  0.6616],\n",
      "         [-0.0174, -0.0404,  0.0223,  ...,  0.0155,  0.0091, -0.0413]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 2.1628e-01, -3.6689e-01, -4.9812e-01,  ..., -3.1371e-01,\n",
      "           3.9327e-01,  6.9357e-01],\n",
      "         [ 6.8227e-01,  1.8098e-01,  1.6720e-01,  ...,  2.9446e-01,\n",
      "           2.2936e-01, -5.2136e-01],\n",
      "         [ 1.5263e+00,  5.6994e-01,  4.2213e-01,  ...,  6.3828e-01,\n",
      "          -9.6981e-01,  3.3614e-01],\n",
      "         ...,\n",
      "         [-1.4674e+00,  7.8286e-01,  2.4790e-01,  ...,  4.6880e-01,\n",
      "          -5.9978e-01, -2.5060e-01],\n",
      "         [-1.2278e+00,  1.1309e+00, -2.0121e-01,  ...,  1.5259e-01,\n",
      "          -7.3778e-01, -1.9138e+00],\n",
      "         [ 5.5690e-03, -3.8597e-02, -1.1969e-02,  ...,  3.8772e-03,\n",
      "          -2.0210e-02, -4.0899e-02]],\n",
      "\n",
      "        [[ 2.4318e-01, -5.2596e-01, -5.4125e-01,  ..., -1.3915e-01,\n",
      "           2.2223e-01,  5.8354e-01],\n",
      "         [ 5.6451e-01,  1.2459e-01,  7.0848e-01,  ...,  3.5983e-01,\n",
      "           2.9672e-01, -5.5536e-01],\n",
      "         [ 2.3776e+00,  9.4025e-01,  6.5911e-01,  ...,  4.0046e-01,\n",
      "          -8.0021e-01, -1.2344e-01],\n",
      "         ...,\n",
      "         [ 1.7884e-01,  6.9589e-02,  3.3930e-02,  ..., -1.0597e-02,\n",
      "           6.9571e-01, -1.2944e-03],\n",
      "         [ 6.8916e-01,  3.8971e-01,  3.7022e-02,  ..., -2.3424e-01,\n",
      "           2.4097e-01,  8.9244e-01],\n",
      "         [ 1.1445e-02, -4.0391e-02, -6.6698e-03,  ...,  5.7427e-03,\n",
      "          -2.0165e-02, -4.4169e-02]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.2028, -0.3390, -0.1676,  ..., -0.1742,  0.3890,  1.1094],\n",
      "         [ 0.6196,  0.2030,  0.1282,  ...,  0.3746,  0.3616, -0.3521],\n",
      "         [ 1.2394,  0.7520,  0.5033,  ...,  1.0842, -0.4682,  0.1903],\n",
      "         ...,\n",
      "         [-1.5839,  0.7820,  0.3723,  ...,  0.4699, -0.1107, -0.3192],\n",
      "         [-1.1248,  0.7186, -0.2436,  ...,  0.0179, -0.4867, -1.5820],\n",
      "         [-0.0031, -0.0352, -0.0078,  ..., -0.0057,  0.0220, -0.0521]],\n",
      "\n",
      "        [[ 0.2959, -0.3541, -0.6547,  ..., -0.0363,  0.6077,  0.5615],\n",
      "         [ 0.4977,  0.1765, -0.0794,  ...,  0.5598,  0.7012, -0.4501],\n",
      "         [ 2.2928,  1.1565,  0.2990,  ...,  0.7065, -0.1105, -0.1272],\n",
      "         ...,\n",
      "         [ 0.0615,  0.3471, -0.0891,  ..., -0.1169,  0.9664,  0.4821],\n",
      "         [ 0.3711,  0.0732, -0.7383,  ...,  0.1108,  0.5227,  0.7674],\n",
      "         [-0.0141, -0.0418, -0.0239,  ..., -0.0097,  0.0327, -0.0602]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 4.1292e-01, -5.4622e-02, -5.0157e-01,  ..., -7.1439e-01,\n",
      "           4.6607e-01,  1.0539e+00],\n",
      "         [ 5.3571e-01,  4.1139e-01, -2.5151e-01,  ...,  2.7454e-01,\n",
      "           5.6216e-01,  3.3817e-01],\n",
      "         [ 1.0175e+00,  6.7412e-01,  7.0450e-01,  ...,  2.1129e-01,\n",
      "           1.7408e-02,  4.1807e-01],\n",
      "         ...,\n",
      "         [-1.5333e+00,  3.8977e-01,  2.4150e-01,  ...,  4.6558e-01,\n",
      "           5.8152e-01, -3.5964e-01],\n",
      "         [-9.1321e-01,  7.2174e-01, -2.2789e-01,  ...,  5.6412e-02,\n",
      "           4.5289e-02, -1.2884e+00],\n",
      "         [ 9.4955e-04, -3.7185e-02,  1.5809e-02,  ..., -4.5941e-02,\n",
      "          -1.9666e-02, -7.3528e-02]],\n",
      "\n",
      "        [[ 2.8309e-01,  1.3549e-01, -8.8523e-01,  ..., -4.9927e-01,\n",
      "           5.2388e-01,  6.0791e-01],\n",
      "         [ 4.8635e-01,  3.2763e-01, -4.7143e-01,  ...,  3.1498e-01,\n",
      "           6.3088e-01,  1.2505e-01],\n",
      "         [ 1.8634e+00,  1.1177e+00,  7.2655e-01,  ...,  1.1974e-01,\n",
      "           2.3865e-01,  3.5358e-01],\n",
      "         ...,\n",
      "         [ 2.5663e-01,  1.1943e-01, -5.9452e-02,  ..., -3.4445e-01,\n",
      "           8.6021e-01,  5.2154e-01],\n",
      "         [-1.4552e-01, -1.7384e-01, -7.8994e-01,  ..., -1.7445e-01,\n",
      "          -1.8410e-01,  5.3319e-01],\n",
      "         [-1.1598e-02, -4.1767e-02,  2.3463e-02,  ..., -4.0192e-02,\n",
      "          -2.7849e-02, -9.3924e-02]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.5008,  0.2269, -0.5118,  ..., -0.5200,  0.2832,  0.8692],\n",
      "         [ 0.5419,  0.6235, -0.3539,  ..., -0.0282,  0.4963,  0.3419],\n",
      "         [ 0.8375,  0.8214,  0.3712,  ...,  0.0638,  0.0147,  0.2802],\n",
      "         ...,\n",
      "         [-1.1949,  0.1524,  0.7388,  ...,  0.2292,  0.3395, -0.1334],\n",
      "         [-0.6110,  0.5662, -0.1860,  ...,  0.2520,  0.0335, -0.9786],\n",
      "         [ 0.0033, -0.0204,  0.0184,  ..., -0.0539, -0.0487, -0.0156]],\n",
      "\n",
      "        [[ 0.2171,  0.3766, -0.5892,  ..., -0.4448,  0.3907,  0.3675],\n",
      "         [ 0.2053,  0.6754, -0.3057,  ...,  0.2911,  0.6554, -0.0365],\n",
      "         [ 1.5063,  1.4088,  0.8182,  ...,  0.0200,  0.5841,  0.1498],\n",
      "         ...,\n",
      "         [ 0.2333,  0.3114, -0.1430,  ..., -0.5253,  0.8699,  0.4649],\n",
      "         [-0.3078,  0.1437, -0.8212,  ..., -0.2975, -0.1149,  0.0215],\n",
      "         [ 0.0255, -0.0075,  0.0286,  ..., -0.0505, -0.0678, -0.0921]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.4518,  0.1972, -0.4294,  ..., -0.3170, -0.3371,  0.6794],\n",
      "         [ 0.6174,  0.1953, -0.0026,  ..., -0.0462,  0.4377, -0.1954],\n",
      "         [ 0.9639,  0.7145,  0.8041,  ..., -0.2706,  0.1283, -0.1311],\n",
      "         ...,\n",
      "         [-1.1051,  0.1430,  0.3951,  ...,  0.7024,  0.0477, -0.2445],\n",
      "         [-0.3018,  0.2063, -0.2390,  ...,  0.7351,  0.0298, -1.0876],\n",
      "         [ 0.0097, -0.0511,  0.0288,  ...,  0.1276, -0.0232, -0.0347]],\n",
      "\n",
      "        [[ 0.2748,  0.2499, -0.4410,  ..., -0.3421, -0.0567,  0.3229],\n",
      "         [ 0.2858,  0.5522, -0.1952,  ...,  0.2977,  0.6269, -0.3012],\n",
      "         [ 1.6457,  1.2286,  0.8697,  ..., -0.2663,  0.9829,  0.0328],\n",
      "         ...,\n",
      "         [ 0.4828,  0.1768, -0.0869,  ..., -0.4198,  0.7256,  0.3343],\n",
      "         [-0.1316, -0.2022, -0.7848,  ...,  0.0211, -0.0276,  0.0983],\n",
      "         [ 0.0087,  0.0027, -0.0078,  ...,  0.1014, -0.0203, -0.0347]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.5262,  0.3111,  0.0635,  ..., -0.5139, -0.2360,  0.1765],\n",
      "         [ 0.6557,  0.1646,  0.0357,  ..., -0.2917,  0.2744, -0.0124],\n",
      "         [ 1.2714,  0.9330,  0.9488,  ..., -0.3509,  0.3581,  0.2470],\n",
      "         ...,\n",
      "         [-1.1342,  0.4081,  0.1333,  ...,  0.6335,  0.0498, -0.0019],\n",
      "         [-0.1300,  0.1144, -0.1573,  ...,  0.5191, -0.0888, -1.0061],\n",
      "         [ 0.0171,  0.0067, -0.0190,  ...,  0.0153, -0.0138,  0.0093]],\n",
      "\n",
      "        [[ 0.1748,  0.3665, -0.1829,  ..., -0.4121,  0.0174,  0.2354],\n",
      "         [ 0.1475,  0.4850, -0.1631,  ..., -0.0864,  0.6014,  0.0495],\n",
      "         [ 1.0484,  1.1951,  0.7417,  ..., -0.7135,  1.0665,  0.3081],\n",
      "         ...,\n",
      "         [ 0.4051,  0.1502,  0.0211,  ..., -0.3017,  0.7728,  0.4167],\n",
      "         [-0.3869, -0.5863, -0.1663,  ...,  0.4047,  0.2398, -0.2340],\n",
      "         [ 0.0233,  0.0112, -0.0166,  ...,  0.0037, -0.0303,  0.0169]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.1219,  0.2386, -0.0089,  ..., -0.3565,  0.2120,  0.2568],\n",
      "         [ 0.3584,  0.1863, -0.2557,  ..., -0.4161,  0.5436,  0.0312],\n",
      "         [ 1.2115,  0.7444,  1.1416,  ..., -0.1788,  0.4152, -0.1766],\n",
      "         ...,\n",
      "         [-1.3715, -0.0884, -0.2859,  ...,  0.5654, -0.0344, -0.1637],\n",
      "         [-0.4437, -0.2219, -0.1582,  ...,  0.6177,  0.3368, -0.4463],\n",
      "         [ 0.6994, -0.0115, -0.0842,  ..., -0.1018, -0.4322, -0.3810]],\n",
      "\n",
      "        [[ 0.0987,  0.3710, -0.1172,  ..., -0.2921,  0.2551,  0.1856],\n",
      "         [ 0.1952,  0.3604, -0.4829,  ...,  0.1172,  0.9087,  0.2542],\n",
      "         [ 0.9428,  0.7529,  0.6970,  ..., -0.5273,  0.7027,  0.0036],\n",
      "         ...,\n",
      "         [ 0.4026, -0.0351,  0.1042,  ..., -0.3336,  0.6649,  0.0607],\n",
      "         [-0.0187, -0.4869, -0.1939,  ...,  0.6178,  0.6148, -0.1918],\n",
      "         [ 0.6716,  0.1270, -0.1164,  ..., -0.2789, -0.5492, -0.3206]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)), past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "y = model.base_model(input_ids=input_ids)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109482240\n",
      "109777152\n"
     ]
    }
   ],
   "source": [
    "print(sum(param.numel() for param in origin_model.parameters())) # 109482240\n",
    "print(sum(param.numel() for param in model.base_model.parameters())) # 109777152\n",
    "# print(sum(param.numel() for param in model.base_model.parameters()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294912\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "for params in model.base_model.parameters():\n",
    "    if params.requires_grad == True:\n",
    "        x += params.numel()\n",
    "\n",
    "print(x) # 294912"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [16]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43minput_ids\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mattention_mask\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m      \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Conada\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\Conada\\lib\\site-packages\\peft\\peft_model.py:823\u001B[0m, in \u001B[0;36mPeftModelForTokenClassification.forward\u001B[1;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, **kwargs)\u001B[0m\n\u001B[0;32m    820\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[0;32m    822\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpeft_config, PromptLearningConfig):\n\u001B[1;32m--> 823\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_model(\n\u001B[0;32m    824\u001B[0m         input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[0;32m    825\u001B[0m         attention_mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[0;32m    826\u001B[0m         inputs_embeds\u001B[38;5;241m=\u001B[39minputs_embeds,\n\u001B[0;32m    827\u001B[0m         labels\u001B[38;5;241m=\u001B[39mlabels,\n\u001B[0;32m    828\u001B[0m         output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[0;32m    829\u001B[0m         output_hidden_states\u001B[38;5;241m=\u001B[39moutput_hidden_states,\n\u001B[0;32m    830\u001B[0m         return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[0;32m    831\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    832\u001B[0m     )\n\u001B[0;32m    834\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m input_ids\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    835\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    836\u001B[0m     \u001B[38;5;66;03m# concat prompt attention mask\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Conada\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "\u001B[1;31mTypeError\u001B[0m: forward() got an unexpected keyword argument 'labels'"
     ]
    }
   ],
   "source": [
    "model(input_ids=input['input_ids'],attention_mask=input['attention_mask'],\n",
    "      labels=label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# TARGET_MODULES = [\n",
    "#     \"query\",\n",
    "#     \"v_proj\",\n",
    "# ]\n",
    "\n",
    "# TARGET_MODULES = \"v_proj\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "embeddings\n",
      "embeddings.word_embeddings\n",
      "embeddings.position_embeddings\n",
      "embeddings.token_type_embeddings\n",
      "embeddings.LayerNorm\n",
      "embeddings.dropout\n",
      "encoder\n",
      "encoder.layer\n",
      "encoder.layer.0\n",
      "encoder.layer.0.attention\n",
      "encoder.layer.0.attention.self\n",
      "encoder.layer.0.attention.self.query\n",
      "encoder.layer.0.attention.self.key\n",
      "encoder.layer.0.attention.self.value\n",
      "encoder.layer.0.attention.self.dropout\n",
      "encoder.layer.0.attention.output\n",
      "encoder.layer.0.attention.output.dense\n",
      "encoder.layer.0.attention.output.LayerNorm\n",
      "encoder.layer.0.attention.output.dropout\n",
      "encoder.layer.0.intermediate\n",
      "encoder.layer.0.intermediate.dense\n",
      "encoder.layer.0.intermediate.intermediate_act_fn\n",
      "encoder.layer.0.output\n",
      "encoder.layer.0.output.dense\n",
      "encoder.layer.0.output.LayerNorm\n",
      "encoder.layer.0.output.dropout\n",
      "encoder.layer.1\n",
      "encoder.layer.1.attention\n",
      "encoder.layer.1.attention.self\n",
      "encoder.layer.1.attention.self.query\n",
      "encoder.layer.1.attention.self.key\n",
      "encoder.layer.1.attention.self.value\n",
      "encoder.layer.1.attention.self.dropout\n",
      "encoder.layer.1.attention.output\n",
      "encoder.layer.1.attention.output.dense\n",
      "encoder.layer.1.attention.output.LayerNorm\n",
      "encoder.layer.1.attention.output.dropout\n",
      "encoder.layer.1.intermediate\n",
      "encoder.layer.1.intermediate.dense\n",
      "encoder.layer.1.intermediate.intermediate_act_fn\n",
      "encoder.layer.1.output\n",
      "encoder.layer.1.output.dense\n",
      "encoder.layer.1.output.LayerNorm\n",
      "encoder.layer.1.output.dropout\n",
      "encoder.layer.2\n",
      "encoder.layer.2.attention\n",
      "encoder.layer.2.attention.self\n",
      "encoder.layer.2.attention.self.query\n",
      "encoder.layer.2.attention.self.key\n",
      "encoder.layer.2.attention.self.value\n",
      "encoder.layer.2.attention.self.dropout\n",
      "encoder.layer.2.attention.output\n",
      "encoder.layer.2.attention.output.dense\n",
      "encoder.layer.2.attention.output.LayerNorm\n",
      "encoder.layer.2.attention.output.dropout\n",
      "encoder.layer.2.intermediate\n",
      "encoder.layer.2.intermediate.dense\n",
      "encoder.layer.2.intermediate.intermediate_act_fn\n",
      "encoder.layer.2.output\n",
      "encoder.layer.2.output.dense\n",
      "encoder.layer.2.output.LayerNorm\n",
      "encoder.layer.2.output.dropout\n",
      "encoder.layer.3\n",
      "encoder.layer.3.attention\n",
      "encoder.layer.3.attention.self\n",
      "encoder.layer.3.attention.self.query\n",
      "encoder.layer.3.attention.self.key\n",
      "encoder.layer.3.attention.self.value\n",
      "encoder.layer.3.attention.self.dropout\n",
      "encoder.layer.3.attention.output\n",
      "encoder.layer.3.attention.output.dense\n",
      "encoder.layer.3.attention.output.LayerNorm\n",
      "encoder.layer.3.attention.output.dropout\n",
      "encoder.layer.3.intermediate\n",
      "encoder.layer.3.intermediate.dense\n",
      "encoder.layer.3.intermediate.intermediate_act_fn\n",
      "encoder.layer.3.output\n",
      "encoder.layer.3.output.dense\n",
      "encoder.layer.3.output.LayerNorm\n",
      "encoder.layer.3.output.dropout\n",
      "encoder.layer.4\n",
      "encoder.layer.4.attention\n",
      "encoder.layer.4.attention.self\n",
      "encoder.layer.4.attention.self.query\n",
      "encoder.layer.4.attention.self.key\n",
      "encoder.layer.4.attention.self.value\n",
      "encoder.layer.4.attention.self.dropout\n",
      "encoder.layer.4.attention.output\n",
      "encoder.layer.4.attention.output.dense\n",
      "encoder.layer.4.attention.output.LayerNorm\n",
      "encoder.layer.4.attention.output.dropout\n",
      "encoder.layer.4.intermediate\n",
      "encoder.layer.4.intermediate.dense\n",
      "encoder.layer.4.intermediate.intermediate_act_fn\n",
      "encoder.layer.4.output\n",
      "encoder.layer.4.output.dense\n",
      "encoder.layer.4.output.LayerNorm\n",
      "encoder.layer.4.output.dropout\n",
      "encoder.layer.5\n",
      "encoder.layer.5.attention\n",
      "encoder.layer.5.attention.self\n",
      "encoder.layer.5.attention.self.query\n",
      "encoder.layer.5.attention.self.key\n",
      "encoder.layer.5.attention.self.value\n",
      "encoder.layer.5.attention.self.dropout\n",
      "encoder.layer.5.attention.output\n",
      "encoder.layer.5.attention.output.dense\n",
      "encoder.layer.5.attention.output.LayerNorm\n",
      "encoder.layer.5.attention.output.dropout\n",
      "encoder.layer.5.intermediate\n",
      "encoder.layer.5.intermediate.dense\n",
      "encoder.layer.5.intermediate.intermediate_act_fn\n",
      "encoder.layer.5.output\n",
      "encoder.layer.5.output.dense\n",
      "encoder.layer.5.output.LayerNorm\n",
      "encoder.layer.5.output.dropout\n",
      "encoder.layer.6\n",
      "encoder.layer.6.attention\n",
      "encoder.layer.6.attention.self\n",
      "encoder.layer.6.attention.self.query\n",
      "encoder.layer.6.attention.self.key\n",
      "encoder.layer.6.attention.self.value\n",
      "encoder.layer.6.attention.self.dropout\n",
      "encoder.layer.6.attention.output\n",
      "encoder.layer.6.attention.output.dense\n",
      "encoder.layer.6.attention.output.LayerNorm\n",
      "encoder.layer.6.attention.output.dropout\n",
      "encoder.layer.6.intermediate\n",
      "encoder.layer.6.intermediate.dense\n",
      "encoder.layer.6.intermediate.intermediate_act_fn\n",
      "encoder.layer.6.output\n",
      "encoder.layer.6.output.dense\n",
      "encoder.layer.6.output.LayerNorm\n",
      "encoder.layer.6.output.dropout\n",
      "encoder.layer.7\n",
      "encoder.layer.7.attention\n",
      "encoder.layer.7.attention.self\n",
      "encoder.layer.7.attention.self.query\n",
      "encoder.layer.7.attention.self.key\n",
      "encoder.layer.7.attention.self.value\n",
      "encoder.layer.7.attention.self.dropout\n",
      "encoder.layer.7.attention.output\n",
      "encoder.layer.7.attention.output.dense\n",
      "encoder.layer.7.attention.output.LayerNorm\n",
      "encoder.layer.7.attention.output.dropout\n",
      "encoder.layer.7.intermediate\n",
      "encoder.layer.7.intermediate.dense\n",
      "encoder.layer.7.intermediate.intermediate_act_fn\n",
      "encoder.layer.7.output\n",
      "encoder.layer.7.output.dense\n",
      "encoder.layer.7.output.LayerNorm\n",
      "encoder.layer.7.output.dropout\n",
      "encoder.layer.8\n",
      "encoder.layer.8.attention\n",
      "encoder.layer.8.attention.self\n",
      "encoder.layer.8.attention.self.query\n",
      "encoder.layer.8.attention.self.key\n",
      "encoder.layer.8.attention.self.value\n",
      "encoder.layer.8.attention.self.dropout\n",
      "encoder.layer.8.attention.output\n",
      "encoder.layer.8.attention.output.dense\n",
      "encoder.layer.8.attention.output.LayerNorm\n",
      "encoder.layer.8.attention.output.dropout\n",
      "encoder.layer.8.intermediate\n",
      "encoder.layer.8.intermediate.dense\n",
      "encoder.layer.8.intermediate.intermediate_act_fn\n",
      "encoder.layer.8.output\n",
      "encoder.layer.8.output.dense\n",
      "encoder.layer.8.output.LayerNorm\n",
      "encoder.layer.8.output.dropout\n",
      "encoder.layer.9\n",
      "encoder.layer.9.attention\n",
      "encoder.layer.9.attention.self\n",
      "encoder.layer.9.attention.self.query\n",
      "encoder.layer.9.attention.self.key\n",
      "encoder.layer.9.attention.self.value\n",
      "encoder.layer.9.attention.self.dropout\n",
      "encoder.layer.9.attention.output\n",
      "encoder.layer.9.attention.output.dense\n",
      "encoder.layer.9.attention.output.LayerNorm\n",
      "encoder.layer.9.attention.output.dropout\n",
      "encoder.layer.9.intermediate\n",
      "encoder.layer.9.intermediate.dense\n",
      "encoder.layer.9.intermediate.intermediate_act_fn\n",
      "encoder.layer.9.output\n",
      "encoder.layer.9.output.dense\n",
      "encoder.layer.9.output.LayerNorm\n",
      "encoder.layer.9.output.dropout\n",
      "encoder.layer.10\n",
      "encoder.layer.10.attention\n",
      "encoder.layer.10.attention.self\n",
      "encoder.layer.10.attention.self.query\n",
      "encoder.layer.10.attention.self.key\n",
      "encoder.layer.10.attention.self.value\n",
      "encoder.layer.10.attention.self.dropout\n",
      "encoder.layer.10.attention.output\n",
      "encoder.layer.10.attention.output.dense\n",
      "encoder.layer.10.attention.output.LayerNorm\n",
      "encoder.layer.10.attention.output.dropout\n",
      "encoder.layer.10.intermediate\n",
      "encoder.layer.10.intermediate.dense\n",
      "encoder.layer.10.intermediate.intermediate_act_fn\n",
      "encoder.layer.10.output\n",
      "encoder.layer.10.output.dense\n",
      "encoder.layer.10.output.LayerNorm\n",
      "encoder.layer.10.output.dropout\n",
      "encoder.layer.11\n",
      "encoder.layer.11.attention\n",
      "encoder.layer.11.attention.self\n",
      "encoder.layer.11.attention.self.query\n",
      "encoder.layer.11.attention.self.key\n",
      "encoder.layer.11.attention.self.value\n",
      "encoder.layer.11.attention.self.dropout\n",
      "encoder.layer.11.attention.output\n",
      "encoder.layer.11.attention.output.dense\n",
      "encoder.layer.11.attention.output.LayerNorm\n",
      "encoder.layer.11.attention.output.dropout\n",
      "encoder.layer.11.intermediate\n",
      "encoder.layer.11.intermediate.dense\n",
      "encoder.layer.11.intermediate.intermediate_act_fn\n",
      "encoder.layer.11.output\n",
      "encoder.layer.11.output.dense\n",
      "encoder.layer.11.output.LayerNorm\n",
      "encoder.layer.11.output.dropout\n",
      "pooler\n",
      "pooler.dense\n",
      "pooler.activation\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "key_list = [key for key, _ in bertModel.named_modules()]\n",
    "for i in list(range(len(key_list))):\n",
    "     # target_module_found = any(key_list[i].endswith(target_key) for target_key in TARGET_MODULES)\n",
    "     # if target_module_found:\n",
    "    print(key_list[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "import loralib as lora\n",
    "# Add a pair of low-rank adaptation matrices with rank r=16\n",
    "layer = lora.Linear(512, 512, r=16)\n",
    "lora.mark_only_lora_as_trainable(bertModel)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.sub(input=y[1],other=x[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 294912 || all params: 109777152 || trainable%: 0.2686460658042941\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertConfig, BertTokenizer\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "bertconfig = BertConfig.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
    "model = BertModel.from_pretrained('bert-base-uncased', config=bertconfig)\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.TOKEN_CLS, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1\n",
    ")\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import loralib as lora\n",
    "\n",
    "# lora.mark_only_lora_as_trainable(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.word_embeddings.weight\n",
      "torch.Size([30522, 768])\n",
      "embeddings.position_embeddings.weight\n",
      "torch.Size([512, 768])\n",
      "embeddings.token_type_embeddings.weight\n",
      "torch.Size([2, 768])\n",
      "embeddings.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "embeddings.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.0.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.0.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.0.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.0.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.0.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.0.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.0.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.0.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.0.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.layer.0.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.0.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "encoder.layer.0.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "encoder.layer.0.output.dense.weight\n",
      "torch.Size([768, 3072])\n",
      "encoder.layer.0.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.0.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.layer.0.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.1.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.1.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.1.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.1.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.1.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.1.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.1.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.1.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.1.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.layer.1.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.1.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "encoder.layer.1.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "encoder.layer.1.output.dense.weight\n",
      "torch.Size([768, 3072])\n",
      "encoder.layer.1.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.1.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.layer.1.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.2.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.2.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.2.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.2.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.2.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.2.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.2.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.2.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.2.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.layer.2.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.2.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "encoder.layer.2.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "encoder.layer.2.output.dense.weight\n",
      "torch.Size([768, 3072])\n",
      "encoder.layer.2.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.2.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.layer.2.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.3.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.3.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.3.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.3.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.3.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.3.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.3.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.3.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.3.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.layer.3.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.3.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "encoder.layer.3.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "encoder.layer.3.output.dense.weight\n",
      "torch.Size([768, 3072])\n",
      "encoder.layer.3.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.3.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.layer.3.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.4.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.4.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.4.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.4.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.4.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.4.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.4.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.4.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.4.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.layer.4.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.4.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "encoder.layer.4.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "encoder.layer.4.output.dense.weight\n",
      "torch.Size([768, 3072])\n",
      "encoder.layer.4.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.4.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.layer.4.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.5.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.5.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.5.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.5.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.5.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.5.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.5.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.5.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.5.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.layer.5.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.5.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "encoder.layer.5.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "encoder.layer.5.output.dense.weight\n",
      "torch.Size([768, 3072])\n",
      "encoder.layer.5.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.5.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.layer.5.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.6.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.6.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.6.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.6.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.6.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.6.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.6.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.6.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.6.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.layer.6.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.6.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "encoder.layer.6.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "encoder.layer.6.output.dense.weight\n",
      "torch.Size([768, 3072])\n",
      "encoder.layer.6.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.6.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.layer.6.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.7.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.7.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.7.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.7.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.7.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.7.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.7.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.7.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.7.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.layer.7.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.7.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "encoder.layer.7.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "encoder.layer.7.output.dense.weight\n",
      "torch.Size([768, 3072])\n",
      "encoder.layer.7.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.7.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.layer.7.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.8.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.8.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.8.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.8.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.8.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.8.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.8.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.8.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.8.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.layer.8.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.8.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "encoder.layer.8.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "encoder.layer.8.output.dense.weight\n",
      "torch.Size([768, 3072])\n",
      "encoder.layer.8.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.8.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.layer.8.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.9.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.9.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.9.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.9.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.9.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.9.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.9.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.9.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.9.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.layer.9.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.9.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "encoder.layer.9.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "encoder.layer.9.output.dense.weight\n",
      "torch.Size([768, 3072])\n",
      "encoder.layer.9.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.9.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.layer.9.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.10.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.10.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.10.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.10.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.10.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.10.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.10.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.10.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.10.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.layer.10.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.10.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "encoder.layer.10.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "encoder.layer.10.output.dense.weight\n",
      "torch.Size([768, 3072])\n",
      "encoder.layer.10.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.10.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.layer.10.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.11.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.11.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.11.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.11.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.11.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.11.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.11.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.layer.11.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.11.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.layer.11.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.11.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "encoder.layer.11.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "encoder.layer.11.output.dense.weight\n",
      "torch.Size([768, 3072])\n",
      "encoder.layer.11.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.layer.11.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.layer.11.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "pooler.dense.weight\n",
      "torch.Size([768, 768])\n",
      "pooler.dense.bias\n",
      "torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "for n, p in model.named_parameters():\n",
    "    print(n)\n",
    "    print(p.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 289, 32])\n"
     ]
    }
   ],
   "source": [
    "from modules.attention.transformer import TransformerEncoder\n",
    "import torch\n",
    "enc = TransformerEncoder(embed_dim=32, num_heads=8, layers=4, attn_mask=False)\n",
    "audio = torch.ones((32, 289, 74))\n",
    "layer = torch.nn.Linear(74, 32)\n",
    "audio = layer(audio)\n",
    "x = enc(audio)\n",
    "print(x.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.Tensor(2, 2, 3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3968.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "n = torch.ones((32, 124, 1))\n",
    "print(torch.sum(n))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from modules.fusion import BottleNeckFusion\n",
    "from config import Config\n",
    "import torch\n",
    "config = Config()\n",
    "fusion = BottleNeckFusion(config)\n",
    "audio = torch.ones((32, 194, 74))\n",
    "visual = torch.ones((32, 268, 35))\n",
    "text = torch.ones((32, 50, 768))\n",
    "a, v, t, result = fusion(audio,visual,text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3577.6467, grad_fn=<AddBackward0>)\n",
      "tensor(2652.1299, grad_fn=<AddBackward0>)\n",
      "tensor(176.9038, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(v)\n",
    "print(t)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "{'audio': tensor(3577.6467, grad_fn=<AddBackward0>),\n 'visual': tensor(2652.1299, grad_fn=<AddBackward0>),\n 'text': tensor(176.9038, grad_fn=<AddBackward0>)}"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_sc = {'audio':a,'visual':v,'text':t}\n",
    "sorted(dict_sc)\n",
    "dict_sc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "audio\n",
      "tensor(3577.6467, grad_fn=<AddBackward0>)\n",
      "1\n",
      "visual\n",
      "tensor(2652.1299, grad_fn=<AddBackward0>)\n",
      "2\n",
      "text\n",
      "tensor(176.9038, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for index, key in enumerate(dict_sc):\n",
    "    print(index)\n",
    "    print(key)\n",
    "    print(dict_sc[key])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(3577.6467, grad_fn=<AddBackward0>), tensor(2652.1299, grad_fn=<AddBackward0>), tensor(176.9038, grad_fn=<AddBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "print(dict_sc[])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.2837])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - torch.tanh(0.3 * torch.relu(torch.tensor([3])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.2837])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - torch.tanh(0.3 * torch.tensor([3]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.0949])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - torch.tanh(0.3 * torch.tensor([5]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2, 3],\n        [4, 5]])"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1,2,3],[3,4,5]])\n",
    "x[:,1:3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}